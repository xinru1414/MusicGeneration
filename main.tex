\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2018

\PassOptionsToPackage{nonatbib}{nips_2018}


% ready for submission
\usepackage[final]{nips_2018}
%\usepackage{nips_2018}

% to compile a preprint version, e.g., for submission to arXiv, add
% add the [preprint] option:
% \usepackage[preprint]{nips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2018}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage[backend=biber]{biblatex}

\addbibresource{main.bib}


\title{Music Generation Using Variational Autoencoder}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Zecong Hu\\
  Language Technologies Institute\\
  Carnegie Mellon University\\
  Pittsburgh, PA 15213 \\
  \texttt{zeconghu@andrew.cmu.edu} \\
  %% examples of more authors
  \And
  Xinru Yan \\
  Language Technologies Institute\\
  Carnegie Mellon University\\
  Pittsburgh, PA 15213 \\
  \texttt{xinruyan@andrew.cmu.edu} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

% \begin{abstract}
%   The abstract paragraph should be indented \nicefrac{1}{2}~inch
%   (3~picas) on both the left- and right-hand margins. Use 10~point
%   type, with a vertical spacing (leading) of 11~points.  The word
%   \textbf{Abstract} must be centered, bold, and in point size 12. Two
%   line spaces precede the abstract. The abstract must be limited to
%   one paragraph.
% \end{abstract}

\section{Project Proposal}

We chose the music generation task as our final project for 10701. We plan to explore deep learning algorithms to generate music. Specifically, we would like to use Variational Autoencoder (VAE) in our project. 

Music generation has gained increasing attention during the past several years in the research community. For example, Johnson used Recurrent Neural Network to generate music \cite{johnson}. Inspired by this model, Huang and Wu built an end-to-end generative model for music generation\cite{huang}. Their results show that a multi-layer LSTM model is capable of learning meaningful musical structure. These research show the potential of using deep learning algorithms in the realm of music generation.

We chose to explore deep latent vector models because they have been applied to creative applications of machine learning increasingly during the recent years \cite{carter}\cite{ha}\cite{engel}. Latent vector models exhibit several desirable properties for our purpose of generating music. Fist, they have strong expressive power, meaning that any real example can be mapped to a point in the latent space hence reconstructed from it. Second, they have strong realization power, meaning that any point in the latent space can be mapped back to the original data space, hence represent some realistic example including ones that are not present in the training set. Last but not the least, they can generate smooth outputs since examples that are close to each other in the latent space share similar qualities. In their research, Bowman et al applied VAE in the area of natural language processing\cite{bowman}. Specifically, they developed a latent vector model to generate coherent and diverse English sentences. Our main inspiration comes from Roberts et al's work\cite{roberts}, which built on the idea of using VAE on sequential data. In their research, they implemented a novel hierarchical latent vector model to learn long-term structure in music. They used western popular music as their input because it exhibits strong long-term structure.  The advantage of the hierarchical latent vector model is that it can capture long-term structure of sequential data such as music.
We plan to implement this architecture in our work. Furthermore, we would like to train this model on different genres of music and compare the generated results.

First we plan to implement this model by using pytorch\cite{pytorch}. To start, we will train the model on publicly available Lakh MIDI Dataset\cite{raffel}\footnote{https://colinraffel.com/projects/lmd/}. Then we plan to collect different styles of music in midi file format as our input to see how the model performs on different style of music. If time permits, we would like to improve the model architecture in order to achieve better performance. Another possibility is to change the model architecture so that we could style transfer the target music that we want to generate given the input music style.

% Such resources can be found here\footnote{https://www.uswebcity.com/midi.html}\footnote{https://figshare.com/articles/Music_Traditional_Chinese_MIDI/5436022}\footnote{http://faculty.pittstate.edu/~yliu/music/Mchinese.html}\footnote{http://www.midis101.com/search/Chinese}.

\section{Introduction}

\section{Background}

\section{Method}

\section{Experiments}

\section{Conclusion}

\section*{References}

\printbibliography


\end{document}